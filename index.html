<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Kaiqi Fu</title>

  <meta name="author" content="Kaiqi Fu">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/pika.jpeg?">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:left">
                    <strong>
                      <name>Kaiqi Fu</name>
                    </strong>
                  </p>
                  <p>
                    I currently work at Zuoyebang Education Technology (Beijing) Co., Ltd, and my main research
                    directions are speech self-supervised
                    models, multimodal models and second language pronunciation assessment. I got my master degree
                    advised by <a href="https://www.researchgate.net/profile/Jinsong-Zhang-3">Jinsong Zhang</a>
                    at Beijing Language and Culture University in July 2021.
                  </p>

                  <p>
                    I'm interested in Speech and Natural Language Processing(NLP). My current research direction is to
                    explore the combination of the two modes.
                  </p>

                  <p style="text-align:center">

                  </p>
                  <p style="text-align:center">
                    Contact: kaiq.fu@gmail.com <br>
                    <!--                Address: 150 Western Ave, Allston, MA 02134 <br>-->
                    <!--                <a href="mailto:ke_li@g.harvard.edu">Email</a> &nbsp|&nbsp-->
                    <!--                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp|&nbsp-->
                    <!--                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp|nbsp-->
                    <a href="https://scholar.google.com.hk/citations?user=5OnauwkAAAAJ&hl=zh-CN">Google Scholar</a>
                    &nbsp|&nbsp
                    <a href="https://github.com/cageyoko">Github</a> &nbsp|&nbsp
                  </p>
                  <p>
                    <strong>I am looking for the meaning of life, such as traveling and fitness!</strong>
                  </p>
                </td>
                <td style="padding:2.5%;width:50%;max-width:50%">
                  <a href="images/kaiqi.jpeg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/kaiqi.jpeg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <h3>Research</h3>

          <!-- Add border="1" here to debug-->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td width="75%" valign="middle">
                  <papertitle>Phonetic and Prosody-aware Self-supervised Learning Approach for Non-native Fluency
                    Scoring</papertitle>
                  <br>
                  <strong>Kaiqi Fu</strong>, Shaojun Gao, Shuju Shi, Xiaohai Tian, Wei Li, Zejun Ma
                  <br>
                  <em>Interspeech</em>, 2023
                  <br>
                  <a href="https://arxiv.org/pdf/2305.11438.pdf">Paper</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td width="75%" valign="middle">
                  <papertitle>Disentangling the Contribution of Non-native Speech in Automated Pronunciation Assessment
                  </papertitle>
                  <br>
                  Shuju Shi, <strong>Kaiqi Fu</strong>, Yiwei Gu, Xiaohai Tian, Shaojun Gao, Wei Li, Zejun Ma
                  <br>
                  <em>Interspeech</em>, 2023
                  <br>
                  <a href="https://arxiv.org/pdf/2305.11438.pdf">Paper</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td width="75%" valign="middle">
                  <papertitle>An ASR-Free Fluency Scoring Approach with Self-Supervised Learning
                  </papertitle>
                  <br>
                  Wei Liu, <strong>Kaiqi Fu</strong>, Xiaohai Tian, Shuju Shi, Wei Li, Zejun Ma, Tan Lee.
                  <br>
                  <em>ICASSP</em>, 2023
                  <br>
                  <a href="https://arxiv.org/pdf/2305.11438.pdf">Paper</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td width="75%" valign="middle">
                  <papertitle>Leveraging phone-level linguistic-acoustic similarity for utterance-level pronunciation
                    scoring
                  </papertitle>
                  <br>
                  Wei Liu, <strong>Kaiqi Fu</strong>, Xiaohai Tian, Shuju Shi, Wei Li, Zejun Ma, Tan Lee.
                  <br>
                  <em>ICASSP</em>, 2023
                  <br>
                  <a href="https://arxiv.org/pdf/2305.11438.pdf">Paper</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td width="75%" valign="middle">
                  <papertitle>Using Fluency Representation Learned from Sequential Raw Features for Improving Non-native
                    Fluency Scoring</papertitle>
                  <br>
                  <strong>Kaiqi Fu</strong>, Shaojun Gao, Xiaohai Tian, Wei Li, Zejun Ma.
                  <br>
                  <em>Interspeech</em>, 2022
                  <br>
                  <a
                    href="https://www.researchgate.net/profile/Kaiqi-Fu-2/publication/363213484_Using_Fluency_Representation_Learned_from_Sequential_Raw_Features_for_Improving_Non-native_Fluency_Scoring/links/63280c520a70852150050538/Using-Fluency-Representation-Learned-from-Sequential-Raw-Features-for-Improving-Non-native-Fluency-Scoring.pdf">Paper</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td width="75%" valign="middle">
                  <papertitle>A Transfer and Multi-Task Learning based Approach for MOS Prediction</papertitle>
                  <br>
                  Xiaohai Tian, <strong>Kaiqi Fu</strong>, Shaojun Gao, Yiwei Gu, Kai Wang, Wei Li, Zejun Ma.
                  <br>
                  <em>Interspeech</em>, 2022
                  <br>
                  <a
                    href="https://www.researchgate.net/profile/Kaiqi-Fu-2/publication/363213484_Using_Fluency_Representation_Learned_from_Sequential_Raw_Features_for_Improving_Non-native_Fluency_Scoring/links/63280c520a70852150050538/Using-Fluency-Representation-Learned-from-Sequential-Raw-Features-for-Improving-Non-native-Fluency-Scoring.pdf">Paper</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td width="75%" valign="middle">
                  <papertitle>Improving Non-native Word-level Pronunciation Scoring with Phone-level Mixup Data
                    Augmentation and Multi-source
                    Information
                  </papertitle>
                  <br>
                  <strong>Kaiqi Fu</strong>, Shaojun Gao, Kai Wang, Wei Li, Xiaohai Tian.
                  <br>
                  <em>Arxiv</em>, 2022
                  <br>
                  <a href="https://arxiv.org/pdf/2203.01826.pdf">Paper</a>
                </td>
              </tr>

              <tr>
                <td width="75%" valign="middle">
                  <papertitle>Non-native acoustic modeling for mispronunciation verification based on language
                    adversarial representation learning
                  </papertitle>
                  <br>
                  Longfei Yang <strong>Kaiqi Fu</strong>, Jinsong Zhang, Takahiro Shinozaki.
                  <br>
                  <em>Neural Networks</em>, 2021
                  <br>
                  <a href="https://arxiv.org/pdf/2203.01826.pdf">Paper</a>
                </td>
              </tr>

              <tr>
                <td width="75%" valign="middle">
                  <papertitle>A Study on Fine-Tuning wav2vec2. 0 Model for the Task of Mispronunciation Detection and
                    Diagnosis</papertitle>
                  <br>
                  Linkai Peng, <strong>Kaiqi Fu</strong>, Binghuai Lin, Dengfeng Ke, Jinsong Zhang.
                  <br>
                  <em>Interspeech</em>, 2021
                  <br>
                  <a
                    href="https://www.researchgate.net/profile/Kaiqi-Fu-2/publication/363213484_Using_Fluency_Representation_Learned_from_Sequential_Raw_Features_for_Improving_Non-native_Fluency_Scoring/links/63280c520a70852150050538/Using-Fluency-Representation-Learned-from-Sequential-Raw-Features-for-Improving-Non-native-Fluency-Scoring.pdf">Paper</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td width="75%" valign="middle">
                  <papertitle>A Full Text-Dependent End to End Mispronunciation Detection and Diagnosis with Easy Data
                    Augmentation Techniques</papertitle>
                  <br>
                  <strong>Kaiqi Fu</strong>, Jones Lin, Dengfeng Ke, Yanlu Xie, Jinsong Zhang.
                  <br>
                  <em>Arxiv</em>, 2021
                  <br>
                  <a href="https://arxiv.org/pdf/2104.08428.pdf">Paper</a> | <a
                    href="https://github.com/cageyoko/CTC-Attention-Mispronunciation">Code</a>
                  <br>Utilizing pronunciation prompt information to model phone-level pronunciation error detection.
                  <p></p>
                </td>
              </tr>

              <tr>
                <td width="75%" valign="middle">
                  <papertitle>Pronunciation Erroneous Tendency Detection with Language Adversarial Represent Learning.
                  </papertitle>
                  <br>
                  Longfei Yang <strong>Kaiqi Fu</strong>, Jinsong Zhang, Takahiro Shinozaki.
                  <br>
                  <em>Interspeech</em>, 2020
                  <br>
                  <a href="https://arxiv.org/pdf/2203.01826.pdf">Paper</a>
                </td>
              </tr>


            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:center;font-size:small;">
                    <!-- Template from <a href="https://https://jonbarron.info/">Jon Barron's website</a> -->
                    <br>
                    Latest update: 09/2023
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>